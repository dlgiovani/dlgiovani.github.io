<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><link rel="icon" type="image/svg+xml" href="/icon-32.png"><meta name="viewport" content="width=device-width"><meta name="generator" content="Astro v5.14.4"><title>Built-In Chrome AI: Making the assistant remember the previous conversation (context aware).</title><style>@font-face{font-family:Inter;src:url(/fonts/Inter/Inter-VariableFont_opsz,wght.ttf)}:root,:root[data-theme=dark]:has(#dark-mode-toggle:checked){--bg: #eaeaea;--fg: #212121;--link: #0784b5;--visited: #0784b5;--pc: #fca;--sc: #cca;@media (prefers-color-scheme: dark){--bg: #212121;--fg: #e3e3e3;--link: #aaf;--visited: #d8f;--pc: #a42;--sc: #442}}*{box-sizing:border-box;font-family:Inter,sans-serif;font-optical-sizing:auto;font-weight:300;font-style:normal;font-variation-settings:"wdth" 100;scroll-behavior:smooth}strong{font-weight:400}body{width:fit-content;margin:2rem auto auto;padding:.4rem;background-color:var(--bg);color:var(--fg)}main{margin-top:25vh;width:100dvw;@media screen and (min-width: 768px){width:80dvw}>section:first-of-type{margin-bottom:20vh}}body>nav{position:fixed;z-index:1000;background:var(--bg);width:100%;top:0;left:0;padding:0 10vw;display:flex;justify-content:space-between;align-items:center;@media screen and (min-width: 768px){padding-top:1rem}}nav{>ul{display:flex;justify-content:stretch;flex-wrap:wrap;list-style-type:none;padding-left:0;gap:2rem;>li{width:fit-content}}}section{padding:.5rem}section:has(a):has(article):not(:has(section)){display:grid;grid-template-columns:1fr;gap:2rem;@media screen and (min-width: 768px){grid-template-columns:1fr 1fr}@media screen and (min-width: 1280px){grid-template-columns:1fr 1fr 1fr 1fr}>a:has(article){display:flex;color:var(--fg)!important;text-decoration:none;width:100%;&:hover{>article>h2{text-decoration:underline;color:var(--link)}}>article{text-align:left;width:100%;>h2,p{overflow:hidden;text-overflow:ellipsis;display:-webkit-box;-webkit-line-clamp:3;line-clamp:3;-webkit-box-orient:vertical}>p{margin-bottom:1rem}>img{width:100%;height:auto;aspect-ratio:16/9;border-radius:1.2rem}}}}article{position:relative;>img{object-fit:cover}}main>article{max-width:60rem;text-wrap:pretty!important;display:flex;flex-direction:column;>img+a{text-align:center}>img,>p>img{margin-top:10px;width:55rem;max-width:100%;height:auto;aspect-ratio:16/9;border-radius:1.2rem;object-fit:contain;object-position:center;background-color:#0000001a}>img{object-fit:cover}>p:has(img){text-align:center;font-size:.9rem;font-weight:200;max-width:none;width:fit-content;display:flex;flex-direction:column}>h1{margin-bottom:1rem}>p:first-of-type{margin-top:2rem}>p+*{margin-top:1rem}}h1{margin:0;font-size:3rem;@media screen and (min-width: 768px){transform:translate(-4px);font-size:4rem}}p{margin:0;max-width:75ch;font-size:1.2rem;&:has(+h1){font-size:2rem}+*{margin-top:.5rem}}em{font-style:italic}ul:has(a){list-style-type:none;padding-left:0}label{text-wrap:nowrap;&:has(>input[type=checkbox]){user-select:none}}a{&:link{color:var(--link)}&:visited{color:var(--visited)}}pre{padding:.7rem 1rem;border-radius:1rem}*{&:has(>aside:only-of-type){display:grid;@media screen and (min-width: 768px){grid-template-columns:1fr 250px;grid-template-rows:auto auto}>aside{grid-row:1 / -1;position:relative;top:0;>ul,ol{position:sticky;top:15dvh}@media screen and (min-width: 768px){grid-column:2}}}}table,th,td,caption{border:1px solid;border-collapse:collapse}caption{background-color:var(--pc)}table{width:100%}tfoot{background-color:var(--sc)}middots{width:100%;height:2rem;margin:1rem 0;display:flex;justify-content:center;font-size:2rem}button{margin:1rem 0;font-size:1rem;padding:.2rem .4rem}footer{margin-top:5vh;bottom:1rem;>section>p{font-size:.8rem;max-width:none}>section{display:flex;flex-wrap:wrap;justify-content:space-evenly;align-items:center}}footer figure{display:flex;flex-direction:row;align-items:center;gap:.5rem;margin:0}footer figure svg{width:80px;height:80px;color:var(--fg)}footer figure figcaption{display:flex;flex-direction:column;align-items:end;font-size:1.4rem;line-height:1.3}footer figure figcaption span{font-size:.8rem;opacity:.8}code:not([class]):not(pre>code){background-color:var(--sc);font-family:monospace;padding:0 .2rem;font-weight:500}
</style></head> <body> <nav> <img src="/icon-48.png" loading="eager" alt="Giovani" decoding="async" fetchpriority="auto" width="32" height="32"> <ul> <li> <a href="/"> Home </a> </li> <li> <a href="/blog"> Blog </a> </li> <li> <a href="/#about"> About </a> </li> </ul> </nav> <main>  <aside id="blog-menu"></aside> <article> <h1>Built-In Chrome AI: Making the assistant remember the previous conversation (context aware).</h1> <time>Sunday, March 24, 2024</time>  <img src="/blog/ai-robot.webp" loading="eager" alt="Built-In Chrome AI: Making the assistant remember the previous conversation (context aware)." inferSize="true" decoding="async" fetchpriority="auto" width="100" height="100"> <a href="https://www.pexels.com/photo/high-angle-photo-of-robot-2599244/">Photo by Alex Knight</a>  <blockquote>
<p>Go to ‚ÄúThe solution‚Äù if you‚Äôre in a hurry.</p>
</blockquote>
<p><strong>[DEPRECATED] Since a recent update, there is a better method to make the assistant context aware. Check the official docs.</strong></p>
<p><middots>¬∑ ¬∑ ¬∑</middots></p>
<p>So, recently Chrome launched for developers and enthusiasts the new built-in version of Gemini on the app, an offline assistant running on your machine.</p>
<p>To access this API, make sure you are using a version of Chrome that is compatible (Canary or Dev ‚â• 128). The options are listed for download below:</p>
<ul>
<li><a href="https://www.google.com/chrome/canary/">canary (nightly builds)</a></li>
<li><a href="https://www.google.com/chrome/dev/">dev (for devs)</a></li>
</ul>
<p>Once you download one of them, go to <strong>chrome://flags</strong> (write this on the url bar) and set:</p>
<ul>
<li><strong>Enables optimization guide on device</strong> to <em>Enabled BypassPerfRequirements</em>;</li>
<li><strong>Prompt API for Gemini Nano</strong> to <em>Enabled</em></li>
</ul>
<p>After that, relaunch Chrome. Then open it again and go to <strong>chrome://components</strong></p>
<p>There you should see a component called <strong>Optimization Guide On Device Model</strong>. Download it. (around 1.5 gigabytes, take care).</p>
<p>If it doesn‚Äôt show up, press <strong>f12</strong> and go to the console. Write:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="javascript"><code><span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">await</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> window</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">ai</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#88C0D0;--shiki-dark:#88C0D0">createTextSession</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">()</span></span></code></pre>
<p>and press Enter. You should see the <strong>Optimization Guide On Device Model</strong> show up on the components list.</p>
<p>After that, relaunch chrome and, if it‚Äôs all correct, this message will disappear so you can use the AI.</p>
<p><middots>¬∑ ¬∑ ¬∑</middots></p>
<h2 id="how-to-setup-the-basics">How to setup the basics</h2>
<p>Before making the local version of Gemini Nano remember our conversation, you gotta setup a simple proof that it works. Paste this on your console:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="javascript"><code><span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">const</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> canCreate</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> =</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> await</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> window</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">ai</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#88C0D0;--shiki-dark:#88C0D0">canCreateTextSession</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">()</span><span style="color:#81A1C1;--shiki-dark:#81A1C1">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">if</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF"> (</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">canCreate</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> !==</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4"> "</span><span style="color:#A3BE8C;--shiki-dark:#A3BE8C">no</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">"</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">) </span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">{</span></span>
<span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">  const</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> session</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> =</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> await</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> window</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">ai</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#88C0D0;--shiki-dark:#88C0D0">createTextSession</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">()</span><span style="color:#81A1C1;--shiki-dark:#81A1C1">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#616E88;--shiki-dark:#616E88">  // Prompt the model and stream the result:</span></span>
<span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">  const</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> stream</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> =</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> session</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#88C0D0;--shiki-dark:#88C0D0">promptStreaming</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">(</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">"</span><span style="color:#A3BE8C;--shiki-dark:#A3BE8C">Write me an extra-long poem</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">"</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">)</span><span style="color:#81A1C1;--shiki-dark:#81A1C1">;</span></span>
<span class="line"><span style="color:#81A1C1;--shiki-dark:#81A1C1">  for</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> await</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF"> (</span><span style="color:#81A1C1;--shiki-dark:#81A1C1">const</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> chunk</span><span style="color:#81A1C1;--shiki-dark:#81A1C1"> of</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9"> stream</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">) </span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">{</span></span>
<span class="line"><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">    console</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">.</span><span style="color:#88C0D0;--shiki-dark:#88C0D0">log</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">(</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">chunk</span><span style="color:#D8DEE9FF;--shiki-dark:#D8DEE9FF">)</span><span style="color:#81A1C1;--shiki-dark:#81A1C1">;</span></span>
<span class="line"><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">  }</span></span>
<span class="line"><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">}</span></span></code></pre>
<p><img src="https://cdn-images-1.medium.com/max/960/1*TPk6ZfvaB2mOCnaQM7KceA.png" alt="a text stream from a generative AI">
You should then see this happening</p>
<p><br>
The problem we are going to solve is that, if you prompt the AI about the past conversation (even from the same session), it can‚Äôt answer you. It does not keep the context.</p>
<p>See an example on the <a href="https://ai-sdk-chrome-ai.vercel.app/">Vercel app</a>:</p>
<p><img src="https://cdn-images-1.medium.com/max/960/1*RjyIQElvn5k7LunxoOSh2Q.png" alt="a conversation with Gemini that shows that it does not supports context keeping naturally.">
no more Ed Sheeran I guess. You were expecting a rickroll, weren‚Äôt you?</p>
<p><br>
As you can notice, it forgot the previous table and responded with a new one out of thin air. This is not what we want, so let‚Äôs fix it.</p>
<h2 id="making-gemini-remember-our-previous-messages">Making Gemini remember our previous messages</h2>
<h3 id="the-research">The Research</h3>
<p>You can provide a context to the built-in AI via the prompt itself. Differently from parameters such as temperature and top-k that you can define when creating a session, the context is fed on each user input.</p>
<p>There is a <strong>special control sequence</strong> that will let us provide the context. On the <a href="https://docs.google.com/document/d/1VG8HIyz361zGduWgNG7R_R8Xkv0OOJ8b5C9QKeCjU0c/edit">official docs</a>, this sequence has the purpose to help the model understand rounds of simulated interactions, a way to guide it to a desired output.</p>
<p><img src="https://cdn-images-1.medium.com/max/960/1*6zbD5A4kkJS3OxZIIj0NBQ.png" alt="the example from the docs">
the example from the docs</p>
<p><br>
As you can see, there is not much about context here.</p>
<p>But I had an intuition that we could extend this function, and based on some research I did about Gemini inner workings, I found a solution to achieve context behaviour with the model.</p>
<h3 id="the-solution">The solution</h3>
<p>On each prompt except for the first, we will pass the string to the <em>prompt</em> function formatted like this:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="typescript"><code><span class="line"><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">`${</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">allPreviousMessages</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">}</span><span style="color:#A3BE8C;--shiki-dark:#A3BE8C"> &#x3C;ctrl23> </span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">${</span><span style="color:#D8DEE9;--shiki-dark:#D8DEE9">currentPrompt</span><span style="color:#ECEFF4;--shiki-dark:#ECEFF4">}`</span></span></code></pre>
<p>We basically start the prompt with the previous messages separated by line breaks, the <strong>special control sequence</strong> (which is literally just the string <em><ctrl23></ctrl23></em>, not a fancy U+whatever symbol), and then finally the actual current prompt. The result of that is an AI aware of its context, as follows:</p>
<p><img src="https://cdn-images-1.medium.com/max/960/1*ZiqeEMOkysKs3wxrBm0n_Q.png" alt="This example shows the AI actually acknowledging the previous messages and taking them into consideration to make a new answer, so it is aware of the context.">
Now we don‚Äôt lose the previous context Also, using markdown on the model texts is a good idea!</p>
<p><br>
You can test it yourself <a href="https://dlgiovani.github.io/chrome-ai-webapp/">here</a>.</p>
<p>Please notice that you need to limit the prompt size for optimal results. Prompts that are in the thousands of characters may break the model.</p>
<p>If you are wondering how the prompts look like, here is the first prompt:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>make a table with 2 songs and its artists</span></span></code></pre>
<p>and here is the second one:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>make a table with 2 songs and its artists</span></span>
<span class="line"><span></span></span>
<span class="line"><span> | Song Title | Artist |</span></span>
<span class="line"><span>|---|---|</span></span>
<span class="line"><span>| "Strawberry Fields Forever" | The Beatles |</span></span>
<span class="line"><span>| "Born This Way" | Lady Gaga |</span></span>
<span class="line"><span></span></span>
<span class="line"><span>     &#x3C;ctrl23></span></span>
<span class="line"><span>add a nirvana song to this table</span></span></code></pre>
<p>And with a third prompt, it would become:</p>
<pre class="astro-code astro-code-themes nord nord" style="background-color:#2e3440ff;--shiki-dark-bg:#2e3440ff;color:#d8dee9ff;--shiki-dark:#d8dee9ff; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>make a table with 2 songs and its artists</span></span>
<span class="line"><span></span></span>
<span class="line"><span> | Song Title | Artist |</span></span>
<span class="line"><span>|---|---|</span></span>
<span class="line"><span>| "Strawberry Fields Forever" | The Beatles |</span></span>
<span class="line"><span>| "Born This Way" | Lady Gaga |</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>add a nirvana song to this table</span></span>
<span class="line"><span></span></span>
<span class="line"><span> | Song Title | Artist |</span></span>
<span class="line"><span>|---|---|</span></span>
<span class="line"><span>| "Strawberry Fields Forever" | The Beatles |</span></span>
<span class="line"><span>| "Born This Way" | Lady Gaga |</span></span>
<span class="line"><span>| "Smells Like Teen Spirit" | Nirvana |</span></span>
<span class="line"><span></span></span>
<span class="line"><span>     &#x3C;ctrl23></span></span>
<span class="line"><span>What are the four seasons?</span></span></code></pre>
<p>We keep growing this prompt until the treshold of 4096 characters, as per the docs. Personally, I wouldn‚Äôt reccommend more than 1000. A 2552 chars long poem broke the model and it was a little annoying to make it work again. This could also be my old notebook‚Äôs fault, though.</p>
<h2 id="thats-all-folks">That‚Äôs all, folks!</h2>
<p>You can see the repository for the context aware version at <a href="https://github.com/dlgiovani/chrome-ai-webapp/tree/main">this link</a>. Leave a star üåüon the repo if you enjoyed!</p>
<p><middots>¬∑ ¬∑ ¬∑</middots></p>
<p>chrome app by me: <a href="https://dlgiovani.github.io/chrome-ai-webapp/">https://dlgiovani.github.io/chrome-ai-webapp/</a> <br>
vercel app: <a href="https://ai-sdk-chrome-ai.vercel.app/">https://ai-sdk-chrome-ai.vercel.app/</a> <br>
repo of my app on github: <a href="https://github.com/dlgiovani/chrome-ai-webapp/tree/main">https://github.com/dlgiovani/chrome-ai-webapp/tree/main</a></p>  </article>  </main> <footer> <hr> <section> <h2>Giovani's Pages</h2> <figure> <svg viewBox="-50 -50 100 100" xmlns="http://www.w3.org/2000/svg"> <circle cx="0" cy="0" r="45" fill="none" stroke="currentColor" stroke-width="2"></circle> <line id="hour-hand" x1="0" y1="0" x2="0" y2="-25" stroke="currentColor" stroke-width="3" stroke-linecap="round"></line> <line id="minute-hand" x1="0" y1="0" x2="0" y2="-35" stroke="currentColor" stroke-width="2" stroke-linecap="round"></line> </svg> <figcaption> <time id="digital-time">00:00</time> <span>in Curitiba, Brazil</span> </figcaption> </figure> </section> <section> <p>&copy; 2025 dlgiovani, made with üß†</p> <p>
Source code
<a href="https://github.com/dlgiovani/dlgiovani.github.io/" target="_blank" rel="noopener noreferrer">
available on GitHub
</a> </p> </section> </footer> <script type="module">function s(){const r=new Date,t=new Date(r.toLocaleString("en-US",{timeZone:"America/Sao_Paulo"})),n=t.getHours(),e=t.getMinutes(),c=t.getSeconds(),u=(e+c/60)*6,m=(n%12+e/60)*30,o=document.getElementById("hour-hand"),i=document.getElementById("minute-hand");o&&o.setAttribute("transform",`rotate(${m})`),i&&i.setAttribute("transform",`rotate(${u})`);const a=document.getElementById("digital-time");if(a){const d=`${n.toString().padStart(2,"0")}:${e.toString().padStart(2,"0")}`;a.textContent=d}}s();setInterval(s,1e3);</script></body></html> <script type="module">document.addEventListener("DOMContentLoaded",()=>{const l=document.getElementById("blog-menu"),e=document.querySelector("main")?.querySelectorAll("*"),d=document.createElement("ol");if(e){for(let t=0;t<e.length-1;t++)if(e[t+1].tagName.toLowerCase()=="h2"){const c=document.createElement("li"),a=e[t],n=e[t+1];a.setAttribute("id",n.textContent);const o=document.createElement("a");o.setAttribute("href",`#${n.textContent}`);const i=document.createTextNode(n.textContent);o.appendChild(i),c.appendChild(o),d.appendChild(c)}l?.appendChild(d)}});</script> <script type="module">document.querySelectorAll("a").forEach(function(t){t.getAttribute("href")?.startsWith("http")&&(t.setAttribute("target","_blank"),t.setAttribute("rel","noopener noreferrer"))});</script>